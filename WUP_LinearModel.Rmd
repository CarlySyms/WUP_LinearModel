---
title: "WUP_LinearModel"
author: "Carly Syms"
date: "4/24/2021"
output: 
  html_document:
    number_sections: true
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
require(tidyverse)
require(tigerstats)
require(rgl)
require(knitr)
if(!require("rglwidget")) {install.packages("rglwidget");require("rglwidget")}
```

```{r}
data <- read.csv(file="https://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="",header=TRUE)  
```

# SIMS~ARM

### ggplot 

```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=ARM))
```
  
### scatterplot

```{r}
basicNN + geom_point() + geom_smooth(method=lm)
```  
  
### Numerical results

```{r}
cor(SIMS~ARM,data=data)
``` 

### Inferential  (Build linear model)
  
```{r}
model.1 <- lm(SIMS~ARM,data=data)
summary.lm(model.1)
```

The line equation is SIMS = 4.1 + .05*ARM.  
The model suggest that r-squared is .467 and another metric, the residual standard error, is 1.226.

### Preductions

```{r}
new <- data.frame(ARM = 88, GRIP = 94)
```
```{r}
predict (model.1, new, interval = "prediction", level = .95)
```

# SIMS~GRIP

### ggplot 

```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=GRIP))
```
  
### scatterplot

```{r}
basicNN + geom_point() + geom_smooth(method=lm)
```  
  
### Numerical results

```{r}
cor(SIMS~GRIP,data=data)
``` 

### Inferential  (Build linear model)
  
```{r}
model.2 <- lm(SIMS~GRIP,data=data)
summary.lm(model.2)
```

The line equation is SIMS = 4.81 + .05*GRIP.  
The model suggest that r-squared is .405 and another metric, the residual standard error, is 1.295.

### Preductions

```{r}
predict (model.2, new, interval = "prediction", level = .95)
```
  
# SIMS~ARM+GRIP

### ggplot 

```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=ARM+GRIP))
```
  
### Numerical results

```{r}
cor(SIMS~ARM+GRIP,data=data)
``` 

### Inferential  (Build linear model)
  
```{r}
model.3 <- lm(SIMS~ARM+GRIP,data=data)
summary.lm(model.3)
```

The line equation is SIMS = -5.4 + .037 * ARM + 0.02 * GRIP 
The model suggest that r-squared is .536 and another metric, the residual standard error, is 1.144. This model is better the other two, because its residual standard error is smaller and the adjusted r-squared is bigger than both. 

### Preductions

```{r}
new <- data.frame(ARM = 88, GRIP = 94)
```

```{r}
predict (model.3, new, interval = "prediction", level = .95)
```
  
# Compare Model1 with Model3

### ANOVA

### Model1 vs Model2

```{r}
anova(model.1,model.2)
```

ANOVA didn't work this time, because model 1 and model 2 are not nested.

### Model1 vs Model3

```{r}
anova(model.1,model.3)
```

The p-value is 0.000004 is very low. So, that means there is a significant difference between the two models. That difference is 29.45, which is significant. Model 2, with ARM and GRIP, is better than the model with just the ARM.

### Medel2 vs Model3

```{r}
anova(model.2,model.3)
```

The p-value is smaller than the previous and is very significant. The difference between the two models is 54, yet with another significant result. 
